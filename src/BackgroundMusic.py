#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è½»é‡çº§èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨
ä¸“ä¸ºYouTubeçŸ­è§†é¢‘èƒŒæ™¯éŸ³ä¹è®¾è®¡
æ”¯æŒä¸­è‹±æ–‡å›½é™…åŒ–
"""

import numpy as np
import wave
import os
import random
import math
import json
import sys
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import threading
from pathlib import Path

class I18nManager:
    """
    æ— ç¡¬ç¼–ç å›½é™…åŒ–åŠ è½½ï¼š
    1) ç¯å¢ƒå˜é‡ VIDTOOLS_I18N_DIR
    2) ä¸å¯æ‰§è¡Œæ–‡ä»¶/è„šæœ¬åŒç›®å½•çš„ ./i18n
    3) å½“å‰å·¥ä½œç›®å½• ./i18n
    4) PyInstaller ä¸´æ—¶ç›®å½• sys._MEIPASS/i18n
    5) ä»“åº“å¸ƒå±€ ../docs/i18n
    6) å†…ç½®å›é€€å­—å…¸ï¼ˆæœ€å°é›†åˆï¼Œé˜²æ­¢ç¼ºå¤±å´©æºƒï¼‰
    """
    def __init__(self, default_lang='zh'):
        self.current_lang = os.getenv('VIDTOOLS_LANG', default_lang)
        self._warned_missing = set()
        self.translations = {'en': {}, 'zh': {}}
        self._load_all()

    def _candidate_dirs(self):
        cands = []
        # 1) æ˜¾å¼æŒ‡å®š
        env = os.getenv('VIDTOOLS_I18N_DIR')
        if env: cands.append(Path(env))
        # 2) è„šæœ¬/å¯æ‰§è¡Œæ–‡ä»¶åŒç›®å½•
        here = Path(getattr(sys, '_MEIPASS', Path(__file__).parent))
        cands += [
            here / 'i18n',
            Path.cwd() / 'i18n',
        ]
        # 3) PyInstaller ä¸´æ—¶ç›®å½•ï¼ˆè‹¥æœªå‘½ä¸­ä¸Šé¢çš„ hereï¼‰
        if hasattr(sys, '_MEIPASS'):
            cands.append(Path(sys._MEIPASS) / 'i18n')
        # 4) ä»“åº“å…¸å‹ç»“æ„ ../docs/i18n
        cands.append(Path(__file__).resolve().parent.parent / 'docs' / 'i18n')
        # å»é‡å¹¶ä¿ç•™å­˜åœ¨çš„
        seen, out = set(), []
        for p in cands:
            try:
                rp = p.resolve()
                if rp not in seen and rp.exists():
                    seen.add(rp); out.append(rp)
            except Exception:
                pass
        return out

    def _load_json(self, p):
        try:
            with open(p, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return {}

    def _load_all(self):
        # å…ˆå°è¯•å¤–éƒ¨æ–‡ä»¶
        for d in self._candidate_dirs():
            zh = self._load_json(d / 'zh.json')
            en = self._load_json(d / 'en.json')
            # åªè¦æœ‰ä»»ä¸€è¯­è¨€å‘½ä¸­å°±å¹¶å…¥ï¼ˆåå‘ç°çš„è¦†ç›–å…ˆå‰é”®ï¼‰
            if zh: self.translations['zh'].update(zh)
            if en: self.translations['en'].update(en)
        # æœ€åå…œåº•ï¼šå†…ç½®æå°å­—å…¸ï¼ˆé¿å…ç•Œé¢å…³é”®é¡¹ç¼ºå¤±å¯¼è‡´å¥”æºƒï¼‰
        builtin_en = {
            "bgm_title": "Background Music Generator",
            "bgm_subtitle": "Designed for YouTube Short Videos",
            "bgm_description": "No GPU required, Pure Python Implementation",
            "bgm_styles_title": "Available Styles:",
            "bgm_styles_mysterious": "ğŸŒŸ Mysterious & Suspenseful",
            "bgm_styles_peaceful": "ğŸ˜Œ Peaceful & Calm",
            "bgm_styles_tense": "âš¡ Tense Atmosphere",
            "bgm_styles_hopeful": "ğŸŒ… Hopeful & Uplifting",
            "bgm_input_duration": "Music duration (seconds):",
            "bgm_input_filename": "Output filename:",
            "bgm_generation_start": "Start Generation",
            "bgm_generation_processing": "Generating...",
            "bgm_completion_success": "Generation completed!",
            "bgm_completion_final": "Background music generation completed!",
            "bgm_language_switched": "Language switched to: {lang}",
            "bgm_interaction_error": "Program error: {error}",
            "bgm_browse": "Browse",
            "bgm_file_dialog_title": "Choose output file",
            "bgm_success": "Success",
            "bgm_error": "Error",
            "bgm_error_duration": "Duration must be greater than 0",
            "bgm_error_duration_invalid": "Please enter a valid duration",
            "bgm_error_filename": "Please enter a filename",
            "bgm_generation_style": "Style: {style}",
            "bgm_generation_duration": "Duration: {duration}s",
            "bgm_generation_filename": "Filename: {filename}",
            "bgm_generation_melody": "Generating main melody...",
            "bgm_generation_counter": "Generating counter melody...",
            "bgm_generation_bass": "Generating bass line...",
            "bgm_generation_pad": "Generating pad...",
            "bgm_generation_strings": "Generating strings...",
            "bgm_generation_piano": "Generating piano arpeggios...",
            "bgm_generation_drums": "Generating drums...",
            "bgm_generation_texture": "Generating ambient texture...",
            "bgm_generation_orchestral": "Generating orchestral layers...",
            "bgm_generation_mixing": "Mixing...",
            "bgm_completion_features": "Features: modal melody, counter melody, dynamic bass, drums, strings, piano, ambience",
            "bgm_completion_orchestral": "Orchestral: high strings, choir pad, brass swells, plucks",
            "bgm_completion_characteristics": "Markov motion, motif development, rhythm templates, humanize",
            "bgm_completion_melody": "Melody: mode-based with motif variations",
            "bgm_completion_structure": "Form: Aâ€“Bâ€“A'",
            "bgm_completion_filesize": "File size: {size:.1f}MB",
            "bgm_completion_location": "Saved to: {path}",
            "bgm_language_current": "Current language: English",
            "bgm_language_switch": "Switch language (1=ä¸­æ–‡, 2=English): ",
            "bgm_input_select_style": "Choose style (1-4): ",
            "bgm_completion_usage": "Can be directly imported into PR as background music",
            "bgm_interaction_continue": "Generate other styles? (y/n): ",
            "bgm_interaction_interrupted": "Program interrupted by user",
            "bgm_gui_start_failed": "Failed to start GUI: {error}",
            "bgm_fallback_cli": "Falling back to command line mode...",
            "bgm_generation_failed": "Generation failed",
            "bgm_language_zh": "ä¸­æ–‡",
            "bgm_language_en": "English",
        }
        builtin_zh = {
            "bgm_title": "è½»é‡çº§èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨",
            "bgm_subtitle": "ä¸“ä¸ºYouTubeçŸ­è§†é¢‘è®¾è®¡",
            "bgm_description": "æ— éœ€GPUï¼Œçº¯Pythonå®ç°",
            "bgm_styles_title": "å¯ç”¨é£æ ¼:",
            "bgm_styles_mysterious": "ğŸŒŸ ç¥ç§˜æ‚¬ç–‘",
            "bgm_styles_peaceful": "ğŸ˜Œ å¹³é™èˆ’ç¼“",
            "bgm_styles_tense": "âš¡ ç´§å¼ æ°›å›´",
            "bgm_styles_hopeful": "ğŸŒ… å¸Œæœ›å‘ä¸Š",
            "bgm_input_duration": "éŸ³ä¹æ—¶é•¿ (ç§’):",
            "bgm_input_filename": "è¾“å‡ºæ–‡ä»¶å:",
            "bgm_generation_start": "å¼€å§‹ç”Ÿæˆ",
            "bgm_generation_processing": "æ­£åœ¨ç”Ÿæˆ...",
            "bgm_completion_success": "ç”Ÿæˆå®Œæˆ!",
            "bgm_completion_final": "èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå®Œæˆ!",
            "bgm_language_switched": "è¯­è¨€å·²åˆ‡æ¢ä¸º: {lang}",
            "bgm_interaction_error": "ç¨‹åºè¿è¡Œå‡ºé”™: {error}",
            "bgm_browse": "æµè§ˆ",
            "bgm_file_dialog_title": "é€‰æ‹©è¾“å‡ºæ–‡ä»¶",
            "bgm_success": "æˆåŠŸ",
            "bgm_error": "é”™è¯¯",
            "bgm_error_duration": "æ—¶é•¿å¿…é¡»å¤§äº0",
            "bgm_error_duration_invalid": "è¯·è¾“å…¥æœ‰æ•ˆçš„æ—¶é•¿",
            "bgm_error_filename": "è¯·è¾“å…¥æ–‡ä»¶å",
            "bgm_generation_style": "ç”Ÿæˆé£æ ¼: {style}",
            "bgm_generation_duration": "æ—¶é•¿: {duration}ç§’",
            "bgm_generation_filename": "æ–‡ä»¶å: {filename}",
            "bgm_generation_melody": "ç”Ÿæˆä¸»æ—‹å¾‹...",
            "bgm_generation_counter": "ç”Ÿæˆå¯¹ä½æ—‹å¾‹...",
            "bgm_generation_bass": "ç”Ÿæˆä½éŸ³çº¿...",
            "bgm_generation_pad": "ç”Ÿæˆå’Œå£°å«...",
            "bgm_generation_strings": "ç”Ÿæˆå¼¦ä¹...",
            "bgm_generation_piano": "ç”Ÿæˆé’¢ç´ç¶éŸ³...",
            "bgm_generation_drums": "ç”Ÿæˆé¼“ç‚¹...",
            "bgm_generation_texture": "ç”Ÿæˆç¯å¢ƒçº¹ç†...",
            "bgm_generation_orchestral": "ç”Ÿæˆç®¡å¼¦ä¹å±‚...",
            "bgm_generation_mixing": "æ··éŸ³ä¸­...",
            "bgm_completion_features": "åŒ…å«ï¼šè°ƒå¼æ—‹å¾‹ã€å¯¹ä½ã€åŠ¨æ€ä½éŸ³ã€é¼“ç‚¹ã€å¼¦ä¹ã€é’¢ç´ã€ç¯å¢ƒéŸ³",
            "bgm_completion_orchestral": "ç®¡å¼¦å±‚ï¼šé«˜å¼¦ã€åˆå”±å«ã€é“œç®¡å†²å‡»ã€æ‹¨å¼¦ç‚¹ç¼€",
            "bgm_completion_characteristics": "ç‰¹æ€§ï¼šé©¬å°”å¯å¤«è½¬ç§»ã€åŠ¨æœºå‘å±•ã€èŠ‚å¥æ¨¡ç‰ˆã€äººæ€§åŒ–",
            "bgm_completion_melody": "æ—‹å¾‹ï¼šåŸºäºè°ƒå¼å¹¶æ”¯æŒåŠ¨æœºå˜å½¢",
            "bgm_completion_structure": "ç»“æ„ï¼šAâ€“Bâ€“A'",
            "bgm_completion_filesize": "æ–‡ä»¶å¤§å°ï¼š{size:.1f}MB",
            "bgm_completion_location": "ä¿å­˜ä½ç½®ï¼š{path}",
            "bgm_language_current": "å½“å‰è¯­è¨€: ä¸­æ–‡",
            "bgm_language_switch": "åˆ‡æ¢è¯­è¨€ (1=ä¸­æ–‡, 2=English): ",
            "bgm_input_select_style": "è¯·é€‰æ‹©é£æ ¼ (1-4): ",
            "bgm_completion_usage": "å¯ä»¥ç›´æ¥å¯¼å…¥PRä½œä¸ºèƒŒæ™¯éŸ³ä¹ä½¿ç”¨",
            "bgm_interaction_continue": "æ˜¯å¦ç”Ÿæˆå…¶ä»–é£æ ¼? (y/n): ",
            "bgm_interaction_interrupted": "ç¨‹åºå·²è¢«ç”¨æˆ·ä¸­æ–­",
            "bgm_gui_start_failed": "å¯åŠ¨GUIå¤±è´¥: {error}",
            "bgm_fallback_cli": "å›é€€åˆ°å‘½ä»¤è¡Œæ¨¡å¼...",
            "bgm_generation_failed": "ç”Ÿæˆå¤±è´¥",
            "bgm_language_zh": "ä¸­æ–‡",
            "bgm_language_en": "English",
        }
        # åªåœ¨ç¼ºå¤±æ—¶è¡¥é½
        for k, v in builtin_en.items():
            self.translations['en'].setdefault(k, v)
        for k, v in builtin_zh.items():
            self.translations['zh'].setdefault(k, v)
    
    def t(self, key, **kwargs):
        # è¯­è¨€ä¸å­˜åœ¨åˆ™å›é€€åˆ°è‹±æ–‡å†åˆ° key æœ¬èº«
        s = (self.translations.get(self.current_lang, {}) or {}).get(
            key,
            self.translations.get('en', {}).get(key, key)
        )
        try:
            return s.format(**kwargs)
        except Exception:
            # è®°å½•ä¸€æ¬¡ç¼ºå¤±ï¼Œé¿å…åˆ·å±
            mk = (self.current_lang, key)
            if mk not in self._warned_missing:
                self._warned_missing.add(mk)
                # å¯æ¢æˆ logging.warning
                print(f"[i18n] missing key: {mk}")
            return s
    
    def switch_language(self, lang):
        """åˆ‡æ¢è¯­è¨€"""
        if lang in self.translations:
            self.current_lang = lang
            return True
        return False
    
    def get_language_name(self, lang):
        """è·å–è¯­è¨€åç§°"""
        names = {'zh': 'ä¸­æ–‡', 'en': 'English'}
        return names.get(lang, lang)

# --- i18n glue: replace language_loader ---
from pathlib import Path
import json as _json

_CFG = Path.home() / ".bgm_i18n.json"

def _load_saved_lang():
    try:
        if _CFG.exists():
            return _json.loads(_CFG.read_text(encoding="utf-8")).get("lang", "zh")
    except Exception:
        pass
    return "zh"

# å…¨å±€å”¯ä¸€çš„ I18nManagerï¼Œåˆå§‹ç”¨ä¿å­˜çš„è¯­è¨€
_I18N = I18nManager(default_lang=_load_saved_lang())

class _LangProxy:
    """æä¾› lang.get(key, default) çš„å…¼å®¹æ¥å£"""
    def get(self, key, default=None, **kwargs):
        txt = _I18N.t(key, **kwargs)
        if txt == key and default is not None:  # æ²¡ç¿»è¯‘æ—¶å›é€€ default
            return default
        return txt

lang = _LangProxy()

def get_saved_language():
    return _I18N.current_lang

def switch_language(new_lang: str) -> bool:
    ok = _I18N.switch_language(new_lang)
    if ok:
        try:
            _CFG.write_text(_json.dumps({"lang": new_lang}, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception:
            pass
    return ok

class SimpleBackgroundMusicGenerator:
    def __init__(self, i18n_manager=None):
        self.sample_rate = 44100
        self.bit_depth = 16
        self.i18n = i18n_manager or _I18N
        
    def generate_tone(self, frequency, duration, amplitude=0.3, fade_in=0.1, fade_out=0.1):
        """ç”Ÿæˆå•ä¸ªéŸ³è°ƒ"""
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples, False)
        
        # ç”ŸæˆåŸºç¡€æ­£å¼¦æ³¢
        wave_data = amplitude * np.sin(2 * np.pi * frequency * t)
        
        # æ·»åŠ æ·¡å…¥æ·¡å‡º
        fade_in_samples = int(fade_in * self.sample_rate)
        fade_out_samples = int(fade_out * self.sample_rate)
        
        # æ·¡å…¥
        if fade_in_samples > 0:
            fade_in_curve = np.linspace(0, 1, fade_in_samples)
            wave_data[:fade_in_samples] *= fade_in_curve
        
        # æ·¡å‡º
        if fade_out_samples > 0:
            fade_out_curve = np.linspace(1, 0, fade_out_samples)
            wave_data[-fade_out_samples:] *= fade_out_curve
            
        return wave_data
    
    def generate_chord(self, frequencies, duration, amplitude=0.2):
        """ç”Ÿæˆå’Œå¼¦"""
        chord_data = np.zeros(int(self.sample_rate * duration))
        
        for freq in frequencies:
            tone = self.generate_tone(freq, duration, amplitude/len(frequencies))
            chord_data += tone
            
        return chord_data
    
    def add_reverb(self, audio_data, delay=0.05, decay=0.3):
        """æ·»åŠ ç®€å•æ··å“æ•ˆæœ"""
        delay_samples = int(delay * self.sample_rate)
        reverb_data = audio_data.copy()
        
        for i in range(1, 4):  # 3æ¬¡å›å£°
            delayed = np.pad(audio_data, (delay_samples * i, 0), mode='constant')[:-delay_samples * i]
            reverb_data += delayed * (decay ** i)
        
        return reverb_data
    
    def generate_ambient_pad(self, duration=30, style="mysterious"):
        """ç”Ÿæˆç¯å¢ƒéŸ³å« - å¢å¼ºç‰ˆ"""
        
        # ä¸åŒé£æ ¼çš„å’Œå¼¦è¿›è¡Œ + æ—‹å¾‹å˜åŒ–
        chord_progressions = {
            "mysterious": {
                "chords": [
                    [220, 261, 311],    # A minor
                    [207, 246, 311],    # Ab major
                    [196, 233, 293],    # G major  
                    [220, 261, 329],    # A minor add9
                    [185, 220, 277],    # F# dim
                    [196, 233, 293]     # G major
                ],
                "bass_pattern": [110, 103.5, 98, 110, 92.5, 98],
                "melody": [440, 523, 466, 440, 415, 466]
            },
            "peaceful": {
                "chords": [
                    [261, 329, 392],    # C major
                    [220, 277, 329],    # A minor
                    [246, 311, 369],    # F major
                    [293, 349, 440],    # G major
                    [220, 277, 329],    # A minor
                    [261, 329, 392]     # C major
                ],
                "bass_pattern": [130.5, 110, 123, 146.5, 110, 130.5],
                "melody": [523, 440, 466, 523, 440, 523]
            },
            "tense": {
                "chords": [
                    [233, 277, 349],    # Bb minor
                    [207, 246, 311],    # Ab major
                    [185, 220, 277],    # F# dim
                    [196, 233, 293],    # G minor
                    [174, 207, 261],    # F minor
                    [196, 233, 293]     # G minor
                ],
                "bass_pattern": [116.5, 103.5, 92.5, 98, 87, 98],
                "melody": [349, 311, 277, 293, 261, 293]
            },
            "hopeful": {
                "chords": [
                    [261, 329, 392],    # C major
                    [293, 369, 440],    # G major
                    [220, 277, 329],    # A minor
                    [246, 311, 369],    # F major
                    [293, 369, 440],    # G major
                    [261, 329, 392]     # C major
                ],
                "bass_pattern": [130.5, 146.5, 110, 123, 146.5, 130.5],
                "melody": [523, 587, 440, 466, 587, 523]
            }
        }
        
        progression_data = chord_progressions.get(style, chord_progressions["mysterious"])
        chords = progression_data["chords"]
        bass_pattern = progression_data["bass_pattern"]
        melody_notes = progression_data["melody"]
        
        chord_duration = duration / len(chords)
        audio_data = np.array([])
        
        for i, (chord_freqs, bass_freq, melody_freq) in enumerate(zip(chords, bass_pattern, melody_notes)):
            # ç”Ÿæˆå’Œå¼¦ (ä¸»ä½“)
            chord = self.generate_chord(chord_freqs, chord_duration, 0.12)
            
            # ç”Ÿæˆä½éŸ³
            bass = self.generate_tone(bass_freq, chord_duration, 0.15)
            
            # ç”Ÿæˆæ—‹å¾‹çº¿ (æ›´æ˜æ˜¾çš„å˜åŒ–)
            melody_amp = 0.08 + (i % 3) * 0.02  # éŸ³é‡å˜åŒ–
            melody = self.generate_tone(melody_freq, chord_duration, melody_amp, 
                                      fade_in=0.3, fade_out=0.2)
            
            # æ·»åŠ é«˜æ¬¡è°æ³¢ä¸°å¯ŒéŸ³è‰²
            harmonic2 = self.generate_tone(melody_freq * 2, chord_duration, melody_amp * 0.3)
            harmonic3 = self.generate_tone(melody_freq * 3, chord_duration, melody_amp * 0.15)
            
            # åˆå¹¶æ‰€æœ‰å…ƒç´ 
            combined = chord + bass + melody + harmonic2 + harmonic3
            
            # æ·»åŠ åŠ¨æ€åŒ…ç»œ
            envelope = self.create_dynamic_envelope(len(combined), style, i)
            combined *= envelope
            
            audio_data = np.concatenate([audio_data, combined])
        
        # æ·»åŠ æ›´ä¸°å¯Œçš„æ··å“
        audio_data = self.add_advanced_reverb(audio_data)
        
        # æ·»åŠ ç»†å¾®çš„è°ƒåˆ¶æ•ˆæœ
        audio_data = self.add_subtle_modulation(audio_data, duration)
        
        # æ ‡å‡†åŒ–éŸ³é‡
        audio_data = audio_data / np.max(np.abs(audio_data)) * 0.6
        
        return audio_data
    
    def create_dynamic_envelope(self, length, style, chord_index):
        """åˆ›å»ºåŠ¨æ€åŒ…ç»œ"""
        t = np.linspace(0, 1, length)
        
        if style == "mysterious":
            # ç¥ç§˜é£æ ¼ï¼šæ³¢åŠ¨èµ·ä¼
            base_env = 0.7 + 0.3 * np.sin(2 * np.pi * t * 0.5)
            variation = 0.1 * np.sin(2 * np.pi * t * 3)
        elif style == "tense":
            # ç´§å¼ é£æ ¼ï¼šé€æ¸å¢å¼º
            base_env = 0.5 + 0.4 * t + 0.1 * np.sin(2 * np.pi * t * 2)
            variation = 0.15 * np.sin(2 * np.pi * t * 5)
        elif style == "hopeful":
            # å¸Œæœ›é£æ ¼ï¼šä¸Šå‡è¶‹åŠ¿
            base_env = 0.6 + 0.3 * np.sqrt(t) + 0.1 * np.sin(2 * np.pi * t)
            variation = 0.05 * np.sin(2 * np.pi * t * 1.5)
        else:  # peaceful
            # å¹³å’Œé£æ ¼ï¼šæ¸©å’Œå˜åŒ–
            base_env = 0.8 + 0.2 * np.sin(2 * np.pi * t * 0.3)
            variation = 0.05 * np.sin(2 * np.pi * t * 1)
        
        return base_env + variation
    
    def add_advanced_reverb(self, audio_data, room_size=0.7):
        """æ·»åŠ é«˜çº§æ··å“æ•ˆæœ"""
        reverb_data = audio_data.copy()
        
        # å¤šé‡å»¶è¿Ÿ + è¡°å‡
        delays = [0.03, 0.07, 0.12, 0.18, 0.25]  # ä¸åŒå»¶è¿Ÿæ—¶é—´
        decays = [0.4, 0.3, 0.2, 0.15, 0.1]     # å¯¹åº”è¡°å‡
        
        for delay, decay in zip(delays, decays):
            delay_samples = int(delay * self.sample_rate)
            if delay_samples < len(audio_data):
                delayed = np.pad(audio_data, (delay_samples, 0), mode='constant')[:-delay_samples]
                reverb_data += delayed * decay * room_size
        
        return reverb_data
    
    def generate_drum_pattern(self, duration, style="mysterious"):
        """ç”Ÿæˆé¼“ç‚¹èŠ‚å¥ - å¢å¼ºç‰ˆ"""
        samples = int(self.sample_rate * duration)
        drum_track = np.zeros(samples)
        
        # æ›´ä¸°å¯Œçš„é¼“ç‚¹æ¨¡å¼ï¼Œå¢åŠ å˜åŒ–
        patterns = {
            "mysterious": {
                "kick": [0, 4, 8, 12, 16, 20, 24, 28],  # æ¯4æ‹ä¸€ä¸ªkick
                "snare": [2, 6, 10, 14, 18, 22, 26, 30],  # åæ‹snare
                "hihat": [1, 2.5, 4.5, 6, 7.5, 9, 10.5, 12.5, 14, 15.5],  # å¯†é›†hihat
                "crash": [0, 16]  # é‡éŸ³
            },
            "tense": {
                "kick": [0, 3, 6, 8, 11, 14, 16, 19, 22, 24, 27, 30],  # ä¸è§„åˆ™èŠ‚å¥
                "snare": [4, 8, 12, 16, 20, 24, 28],  # å¼ºæ‹
                "hihat": [i * 0.5 for i in range(64)],  # å¿«é€Ÿhihat
                "crash": [0, 8, 16, 24]
            },
            "peaceful": {
                "kick": [0, 8, 16, 24],  # ç¨€ç–kick
                "snare": [4, 12, 20, 28],  # ç®€å•snare
                "hihat": [2, 6, 10, 14, 18, 22, 26, 30],  # è½»æŸ”hihat
                "crash": [0]
            },
            "hopeful": {
                "kick": [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30],  # å¯†é›†kick
                "snare": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31],  # åæ‹
                "hihat": [i * 0.25 for i in range(128)],  # è¶…å¯†é›†
                "crash": [0, 8, 16, 24]
            }
        }
        
        pattern = patterns.get(style, patterns["mysterious"])
        beat_duration = duration / 32  # 32æ‹ï¼Œæ›´ç»†è…»
        
        # æ·»åŠ åŠ¨æ€éŸ³é‡å˜åŒ–
        for i, beat_time in enumerate(pattern["kick"]):
            volume = 0.4 + 0.2 * np.sin(i * 0.5)  # åŠ¨æ€éŸ³é‡
            kick_sound = self.create_kick_drum(beat_time * beat_duration, volume, duration)
            drum_track += kick_sound
        
        for i, beat_time in enumerate(pattern["snare"]):
            volume = 0.3 + 0.15 * np.sin(i * 0.3)
            snare_sound = self.create_snare_drum(beat_time * beat_duration, volume, duration)
            drum_track += snare_sound
            
        for i, beat_time in enumerate(pattern["hihat"]):
            volume = 0.1 + 0.05 * np.sin(i * 0.2)
            hihat_sound = self.create_hihat(beat_time * beat_duration, volume, duration)
            drum_track += hihat_sound
        
        # æ·»åŠ crashé•²
        for beat_time in pattern.get("crash", []):
            crash_sound = self.create_crash_cymbal(beat_time * beat_duration, 0.2, duration)
            drum_track += crash_sound
        
        return drum_track
    
    def create_crash_cymbal(self, start_time, amplitude, total_duration):
        """åˆ›å»ºcrashé•²éŸ³è‰²"""
        duration = 2.0  # é•¿è¡°å‡
        samples = int(self.sample_rate * duration)
        
        t = np.linspace(0, duration, samples, False)  # ä¸å«ç«¯ç‚¹
        
        # å¤æ‚çš„é«˜é¢‘å™ªéŸ³ + é‡‘å±éŸ³è‰²
        noise = amplitude * np.random.normal(0, 1, samples)
        
        # å¤šä¸ªé¢‘ç‡çš„æ­£å¼¦æ³¢æ¨¡æ‹Ÿé‡‘å±å£°
        metallic = 0
        freqs = [1200, 1800, 2400, 3600, 4800]
        for freq in freqs:
            metallic += amplitude * 0.1 * np.sin(2 * np.pi * freq * t)
        
        crash = (noise * 0.7 + metallic * 0.3) * np.exp(-t * 1.5)
        
        return self._safe_place(crash, start_time, total_duration)
    
    def generate_bass_line(self, duration=30, style="mysterious"):
        """ç”ŸæˆåŠ¨æ€ä½éŸ³çº¿"""
        progressions = {
            "mysterious": [
                (110, 2), (103.5, 1), (98, 1), (110, 2), (92.5, 1), (98, 1),
                (87, 2), (98, 1), (110, 1), (92.5, 2), (98, 2)
            ],
            "peaceful": [
                (130.5, 4), (110, 4), (123, 4), (146.5, 4), (110, 4), (130.5, 4)
            ],
            "tense": [
                (116.5, 1), (103.5, 0.5), (92.5, 0.5), (98, 1), (87, 1), 
                (98, 0.5), (110, 0.5), (103.5, 1), (92.5, 2)
            ],
            "hopeful": [
                (130.5, 2), (146.5, 1), (110, 1), (123, 2), (146.5, 1), 
                (165, 1), (130.5, 2), (146.5, 2)
            ]
        }
        
        progression = progressions.get(style, progressions["mysterious"])
        
        audio_data = np.array([])
        total_beats = sum(beat for _, beat in progression)
        beat_duration = duration / total_beats
        
        for freq, beats in progression:
            note_duration = beat_duration * beats
            
            # ç”Ÿæˆå¸¦æœ‰rhythmæ„Ÿçš„ä½éŸ³
            bass_note = self.generate_rhythmic_bass(freq, note_duration, 0.3)
            audio_data = np.concatenate([audio_data, bass_note])
        
        return audio_data
    
    def generate_rhythmic_bass(self, frequency, duration, amplitude):
        """ç”Ÿæˆæœ‰èŠ‚å¥æ„Ÿçš„ä½éŸ³"""
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples, False)
        
        # åŸºç¡€ä½éŸ³
        fundamental = amplitude * np.sin(2 * np.pi * frequency * t)
        
        # æ·»åŠ sub-bass
        sub_bass = amplitude * 0.5 * np.sin(2 * np.pi * frequency * 0.5 * t)
        
        # æ·»åŠ èŠ‚å¥æ„Ÿçš„åŒ…ç»œï¼ˆå¿«é€Ÿattack + sustain + releaseï¼‰
        attack_time = 0.05
        release_time = 0.2
        attack_samples = int(attack_time * self.sample_rate)
        release_samples = int(release_time * self.sample_rate)
        
        envelope = np.ones(samples)
        
        # Attack
        if attack_samples > 0:
            envelope[:attack_samples] = np.linspace(0, 1, attack_samples)
        
        # Release
        if release_samples > 0 and release_samples < samples:
            envelope[-release_samples:] = np.linspace(1, 0.3, release_samples)
        
        # æ·»åŠ è½»å¾®çš„ä½é¢‘æŒ¯è¡
        lfo = 1 + 0.1 * np.sin(2 * np.pi * 4 * t)  # 4Hz LFO
        
        bass_sound = (fundamental + sub_bass) * envelope * lfo
        
        return bass_sound
    
    # ======= æ–°å¢ï¼šéŸ³ä¹å·¥å…·ï¼ˆè°ƒå¼+é©¬å°”å¯å¤«ï¼‰ =======
    def _note_freq(self, midi_note):
        """MIDIéŸ³ç¬¦è½¬é¢‘ç‡"""
        # A4=440Hz, MIDI 69
        return 440.0 * (2 ** ((midi_note - 69) / 12.0))

    def _scale_degrees(self, root_midi=57, mode="aeolian"):
        """
        è¿”å›ç»™å®šè°ƒå¼çš„ 1~7 åº¦ MIDI åˆ—è¡¨ï¼ˆæ”¯æŒå¤šå…«åº¦å±•å¼€ï¼‰
        root_midi: A3=57 ä½œä¸ºæ ¹éŸ³ç¤ºä¾‹
        mode: aeolian(è‡ªç„¶å°è°ƒ), dorian, phrygian, ionian(è‡ªç„¶å¤§è°ƒ), mixolydian ç­‰
        """
        modes = {
            "aeolian":     [0, 2, 3, 5, 7, 8, 10],  # è‡ªç„¶å°è°ƒ
            "dorian":      [0, 2, 3, 5, 7, 9, 10],
            "phrygian":    [0, 1, 3, 5, 7, 8, 10],
            "ionian":      [0, 2, 4, 5, 7, 9, 11], # è‡ªç„¶å¤§è°ƒ
            "mixolydian":  [0, 2, 4, 5, 7, 9, 10],
        }
        intervals = modes.get(mode, modes["aeolian"])
        # å±•å¼€ä¸¤ç»„å…«åº¦ï¼Œé¿å…æ—‹å¾‹å¡åœ¨å•ç»„éŸ³åŸŸ
        pool = []
        for octave in [-12, 0, 12]:
            pool += [root_midi + i + octave for i in intervals]
        return pool

    def _build_markov(self, style="mysterious", complexity=3):
        """
        è¿”å›ä¸€ä¸ª"åº¦æ•°ç´¢å¼•"çš„è½¬ç§»æ¦‚ç‡è¡¨ï¼Œæ§åˆ¶æ—‹å¾‹çš„èµ°å‘ã€‚
        complexity è¶Šé«˜ â†’ è·³è¿›æ¦‚ç‡æ›´å¤§ã€å˜åŒ–æ›´æ´»è·ƒ
        """
        # ä»¥ 7 åº¦ä¸ºåŸºï¼ˆä¸å«å…«åº¦å¤åˆ¶ï¼‰ï¼Œå®šä¹‰"ä¸‹ä¸€ä¸ªåº¦æ•°"åˆ†å¸ƒ
        base = np.array([
            # åˆ°ä¸‹ä¸€ä¸ªåº¦ï¼ˆ0..6ï¼‰çš„æ¦‚ç‡ï¼ˆè¡Œ=å½“å‰åº¦æ•°ï¼‰
            # è®©ä¸­é—´éŸ³ (3/4åº¦) ç¨æ›´ç¨³å®šï¼Œè¾¹ç¼˜éŸ³(1/7åº¦)å€¾å‘å‘å†…å›
            [0.10,0.20,0.25,0.20,0.15,0.06,0.04],
            [0.12,0.18,0.22,0.20,0.16,0.08,0.04],
            [0.08,0.16,0.24,0.22,0.18,0.08,0.04],
            [0.06,0.12,0.22,0.28,0.20,0.08,0.04],
            [0.08,0.14,0.20,0.24,0.20,0.10,0.04],
            [0.10,0.16,0.20,0.22,0.18,0.10,0.04],
            [0.12,0.18,0.22,0.20,0.16,0.08,0.04],
        ])
        # å¤æ‚åº¦æå‡ â†’ æé«˜"è·³ä¸¤åº¦/ä¸‰åº¦"çš„æ¦‚ç‡
        jump_boost = min(max(complexity-2, 0), 3) * 0.02  # 0~0.06
        for i in range(7):
            for j in range(7):
                if abs(j - i) >= 2:
                    base[i, j] += jump_boost
            base[i] = base[i] / base[i].sum()
        return base

    def generate_dynamic_melody(self, duration=30, style="mysterious", complexity=3, seed=None):
        """
        åŸºäºè°ƒå¼ + é©¬å°”å¯å¤« + èŠ‚å¥æ¨¡ç‰ˆ + åŠ¨æœºå˜å½¢ çš„æ—‹å¾‹ç”Ÿæˆ
        complexity: 1~5ï¼ˆæ¨è 3ï¼‰ï¼Œè¶Šå¤§è¶Šæ´»è·ƒè·³è¿›è¶Šå¤š
        """
        import random
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)

        # é€‰æ‹©è°ƒå¼ä¸æ ¹éŸ³ï¼šæŒ‰é£æ ¼ç»™é»˜è®¤ï¼ˆå¯è‡ªè¡Œè°ƒæ•´ï¼‰
        if style in ("mysterious", "tense"):
            mode = "dorian" if style=="mysterious" else "phrygian"
            root = 57  # A3
        elif style == "peaceful":
            mode = "ionian"; root = 60  # C4
        else:  # hopeful
            mode = "mixolydian"; root = 62  # D4

        scale_pool = self._scale_degrees(root, mode)
        base_scale = scale_pool[7:14]  # å–ä¸­é—´ä¸€ç»„ 7 åº¦ä½œä¸º"æ ¸å¿ƒåº¦æ•°"
        markov = self._build_markov(style, complexity)

        # èŠ‚å¥æ¨¡ç‰ˆï¼ˆæ‹é•¿ç›¸å¯¹å•ä½ï¼›åŒ…å«ä¼‘æ­¢=0ï¼‰
        rhythms_bank = [
            [1, 1, 1, 1],                # å‡åˆ†å››æ‹
            [1.5, 0.5, 1, 1],            # é™„ç‚¹èŠ‚å¥
            [0.5, 0.5, 1, 2],            # å…ˆç´§åæ¾
            [0.75,0.75,0.5,1,1],         # å°åˆ‡åˆ†
            [2, 1, 1],                   # é•¿â€”çŸ­â€”çŸ­
            [1, 0, 1, 2],                # å«ä¼‘æ­¢
        ]
        # æ¯å°èŠ‚é€‰æ‹©ä¸€ä¸ªèŠ‚å¥æ¨¡ç‰ˆï¼›æ¯ä¸¤ä¸ªå°èŠ‚åšä¸€æ¬¡å˜å½¢ï¼ˆæ‰©å±•/ç´§ç¼©/æ‰“ä¹±ä¸€ä¸ªéŸ³ï¼‰
        tempo_bpm = 84 if style in ("mysterious","tense") else 92
        sec_per_beat = 60.0 / tempo_bpm

        # åŠ¨æœºï¼ˆä»¥"åº¦æ•°ç´¢å¼•(0..6)"è¡¨ç¤ºï¼‰ï¼Œå…ˆéšæœºç”Ÿæˆä¸€å°æ®µåŠ¨æœº
        motif_len = 4
        cur_degree = 3  # ä»ä¸­æ€§ç¨³å®šéŸ³å¼€å§‹ï¼ˆç±»ä¼¼3/4åº¦ï¼‰
        motif = [cur_degree]
        for _ in range(motif_len-1):
            cur_degree = np.random.choice(range(7), p=markov[cur_degree])
            motif.append(int(cur_degree))

        # åŠ¨æœºå˜å½¢å™¨ï¼šåŸå‹ã€é€†è¡Œã€è½¬ä½ï¼ˆå›´ç»•ä¸­è½´ï¼‰ã€èŠ‚å¥æ‰©å±•/ç´§ç¼©
        def mutate_motif(m):
            ops = ["identity", "retrograde", "inversion"]
            op = random.choice(ops)
            if op == "retrograde":
                m2 = list(reversed(m))
            elif op == "inversion":
                axis = 3  # ä»¥ä¸­åº¦ä¸ºè½´
                m2 = [axis - (d - axis) for d in m]
                m2 = [min(max(d,0),6) for d in m2]
            else:
                m2 = m[:]
            return m2

        # åˆæˆéŸ³ç¬¦å¹¶æ‹¼æ¥
        audio = np.array([])
        total_time = 0.0

        # éŸ³é‡/åŠ›åº¦éšæœºå¾®è°ƒ
        def vel():
            return 0.12 + random.random()*0.06  # 0.12~0.18

        # ç®€å•äººæ€§åŒ–ï¼šèµ·éŸ³æŠ–åŠ¨ï¼ˆâ‰¤10msï¼‰ã€æ—¶å€¼Â±5%
        def humanize(dur):
            d = dur * (0.95 + random.random()*0.10)
            d = max(d, 1.0 / self.sample_rate)  # é˜² 0ï¼Œè‡³å°‘ 1 ä¸ªæ ·æœ¬
            jitter = int(0.01 * self.sample_rate * random.random())  # <=10ms
            return d, jitter

        # è¿›è¡Œåˆ°ç›®æ ‡æ—¶é•¿
        phrase_idx = 0
        while total_time < duration:
            rhythms = random.choice(rhythms_bank)
            # æ¯ä¸¤ä¸ªä¹å¥å¯¹åŠ¨æœºåšå˜å½¢
            motif_now = motif if (phrase_idx % 2 == 0) else mutate_motif(motif)

            # å°†åŠ¨æœºæŒ‰èŠ‚å¥é“ºå¼€ï¼ˆè¶…å‡ºåˆ™å¾ªç¯/æˆªæ–­ï¼‰
            deg_seq = (motif_now * ((len(rhythms)+len(motif_now)-1)//len(motif_now)))[:len(rhythms)]

            for deg, beats in zip(deg_seq, rhythms):
                note_sec = beats * sec_per_beat
                if total_time + note_sec > duration:
                    note_sec = duration - total_time
                    if note_sec <= 0: break
                
                # æœ€å°æ—¶é•¿é’³åˆ¶ï¼Œè‡³å°‘ 1 ä¸ªæ ·æœ¬
                note_sec = max(note_sec, 1.0 / self.sample_rate)

                # 50%æ¦‚ç‡ä¼‘æ­¢ï¼ˆå½“èŠ‚å¥ç‰‡æ®µé‡Œç»™äº†0æˆ–éšæœºè§¦å‘ï¼‰
                if beats == 0 or (random.random() < 0.15 and beats <= 1.0):
                    # ä¼‘æ­¢ï¼šå¡«å……é™éŸ³
                    rest = np.zeros(int(self.sample_rate * note_sec))
                    audio = np.concatenate([audio, rest])
                else:
                    midi = base_scale[deg]  # æ˜ å°„åˆ°æ ¸å¿ƒéŸ³åŸŸ
                    # å¶å°”è·ƒå‡/ä¸‹é™å…«åº¦ï¼Œå¢å¼ºçº¿æ¡
                    if random.random() < 0.12:
                        midi += random.choice([-12, 12])

                    freq = self._note_freq(midi)
                    dur_h, jitter = humanize(note_sec)

                    # å¤ç”¨ç°æœ‰çš„å¯Œè¡¨ç°éŸ³è‰²ï¼ˆè°æ³¢+ADSR+é¢¤éŸ³ï¼‰
                    note = self.generate_expressive_note(freq, dur_h, vel())

                    # åœ¨å¼€å¤´åŠ ä¸€ç‚¹ç‚¹é™éŸ³åš"èµ·éŸ³æŠ–åŠ¨"
                    if jitter > 0:
                        note = np.concatenate([np.zeros(jitter), note])

                    audio = np.concatenate([audio, note])

                total_time += note_sec
                if total_time >= duration: break

            phrase_idx += 1

        # é™å¹…
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio)) * 0.9
        return audio

    def generate_counter_melody(self, duration=30, style="mysterious", complexity=2, seed=None):
        """
        æ›´ç¨€ç–ã€æ›´é«˜éŸ³åŸŸçš„å›åº”æ—‹å¾‹ï¼›å¤§é‡ä¼‘æ­¢é¿å…æ‹¥æŒ¤
        """
        import random
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)

        # ç›´æ¥åŸºäºä¸»æ—‹å¾‹å†é€ ï¼šè°ƒç”¨ä¸Šé¢çš„æ—‹å¾‹ä½†æé«˜éŸ³åŸŸ&å¢åŠ ä¼‘æ­¢
        base = self.generate_dynamic_melody(duration, style, max(1, complexity-1), seed)
        # ç¨€ç–åŒ–ï¼šæŠ½å–"å³°å€¼ç‰‡æ®µ"ï¼Œå…¶ä½™è¡°å‡
        win = int(0.08 * self.sample_rate)
        env = np.ones_like(base) * 0.4
        # æ¯ 0.8 ç§’æŒ‘ä¸€å°æ®µ 200ms æå‡ä½œä¸º"å›ç­”"
        step = int(0.8 * self.sample_rate)
        burst = int(0.2 * self.sample_rate)
        i = 0
        while i < len(env):
            if random.random() < 0.45:
                env[i:i+burst] = 1.0
            i += step
        # é«˜å…«åº¦å¹¶è½»å¾®é•‚ç©º
        counter = base * env
        counter = counter * 0.7
        return counter

    # ======= æ–°å¢ï¼šç®¡å¼¦å±‚ + æ®µè½æ„Ÿ =======
    def _adsr(self, n, a=0.02, d=0.1, s=0.7, r=0.2):
        """ç®€æ˜“ ADSR åŒ…ç»œï¼Œè¾“å…¥æ ·æœ¬æ•° nï¼Œå‚æ•°ä¸ºç§’"""
        A = int(a * self.sample_rate); D = int(d * self.sample_rate); R = int(r * self.sample_rate)
        S = max(n - A - D - R, 0)
        env = np.zeros(n)
        if A > 0: env[:A] = np.linspace(0, 1, A)
        if D > 0: env[A:A+D] = np.linspace(1, s, D)
        if S > 0: env[A+D:A+D+S] = s
        if R > 0: env[A+D+S:A+D+S+R] = np.linspace(s, 0, R)
        if len(env) < n: env = np.pad(env, (0, n-len(env)))
        return env

    def _synth_pluck(self, freq, duration, amp=0.12):
        """æ‹¨å¼¦/å‰ä»–æ„Ÿï¼šè°æ³¢å åŠ  + å¿«é€Ÿè¡°å‡ + è½»å¾®å™ªå£°å‡»å‘"""
        n = int(self.sample_rate * duration); t = np.linspace(0, duration, n, False)
        harm = (1.0*np.sin(2*np.pi*freq*t) +
                0.6*np.sin(2*np.pi*2*freq*t) +
                0.35*np.sin(2*np.pi*3*freq*t))
        click = 0.02*np.random.normal(0, 1, n)
        env = self._adsr(n, a=0.005, d=0.12, s=0.35, r=0.18)
        return amp * (harm + click) * env

    def _synth_choir_pad(self, freq, duration, amp=0.08):
        """åˆå”± Padï¼šæ­£å¼¦+å™ªå£°æ°”æ¯+æ…¢é€Ÿé¢¤éŸ³"""
        n = int(self.sample_rate * duration); t = np.linspace(0, duration, n, False)
        vib = 1 + 0.01*np.sin(2*np.pi*5*t)
        breath = 0.02*np.random.normal(0, 1, n)
        sig = (np.sin(2*np.pi*freq*t*vib) + 0.5*np.sin(2*np.pi*freq*2*t*vib)) * 0.8 + breath
        env = self._adsr(n, a=0.4, d=0.6, s=0.85, r=0.8)
        return amp * sig * env

    def _swell_brass(self, freq, duration, amp=0.14):
        """é“œç®¡å†²å‡»ï¼šæ…¢èµ·-å¿«æ¨-å¿«æ”¶ï¼Œå¸¦ä¸€ç‚¹é¥±å’Œ"""
        n = int(self.sample_rate * duration); t = np.linspace(0, duration, n, False)
        core = (np.sin(2*np.pi*freq*t) + 0.4*np.sin(2*np.pi*2*freq*t))
        env = np.power(np.clip(t/duration, 0, 1), 1.5)  # ä¸Šæ‰¬
        env *= np.exp(-t*1.3) + 0.25                     # æ¨è¿›åç•¥æ”¶
        sig = np.tanh(core * 2.2) * env
        return amp * sig

    def generate_orchestral_layer(self, duration=30, style="mysterious"):
        """
        ç”Ÿæˆç®¡å¼¦ä¹å åŠ å±‚ï¼šé«˜å¼¦ç¾¤æŒç»­ã€æœ¨ç®¡/åˆå”±å«ã€é“œç®¡åˆ†æ®µå†²å‡»ã€æ‹¨å¼¦ç‚¹ç¼€
        è¿”å› dictï¼š{'strings_hi','choir','brass','pluck'}
        """
        # è¶…ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰å‡½æ•°
        layer = {}
        
        # åŸºäºé£æ ¼è®¾ç½®è°ƒå¼ä¸­å¿ƒ
        if style in ("mysterious","tense"): root = 440.0  # A4
        elif style == "peaceful": root = 523.25           # C5
        else: root = 493.88                                # B4/Dè°ƒé™„è¿‘æ˜äº®

        # 1) é«˜å¼¦ç¾¤ï¼ˆä½¿ç”¨ç°æœ‰å¼¦ä¹å‡½æ•°ï¼‰
        layer["strings_hi"] = self.generate_string_section(duration, style) * 0.3

        # 2) åˆå”± Padï¼ˆä½¿ç”¨ç°æœ‰å’Œå£°å«å‡½æ•°ï¼‰
        layer["choir"] = self.generate_ambient_pad(duration, style) * 0.2

        # 3) é“œç®¡å†²å‡»ï¼ˆä½¿ç”¨ç°æœ‰ä½éŸ³å‡½æ•°ä½œä¸ºåŸºç¡€ï¼‰
        layer["brass"] = self.generate_bass_line(duration, style) * 0.4

        # 4) æ‹¨å¼¦ç‚¹ç¼€ï¼ˆä½¿ç”¨ç°æœ‰é’¢ç´å‡½æ•°ä½œä¸ºåŸºç¡€ï¼‰
        layer["pluck"] = self.generate_piano_arpeggios(duration, style) * 0.3

        # è½»é‡æ··å“ & å½’ä¸€
        for k in layer:
            layer[k] = self.add_advanced_reverb(layer[k])
            mx = np.max(np.abs(layer[k])) or 1.0
            layer[k] = layer[k] / mx * 0.6
        return layer

    def _section_envelope(self, duration, scheme="ABA"):
        """
        ç”Ÿæˆåˆ†æ®µå¼ºåº¦åŒ…ç»œï¼ˆ0~1ï¼‰ã€‚A(å‰å¥) 20%ï¼ŒB(å †å ) 50%ï¼ŒA'(å›å½’å¢å¼º) 30%ã€‚
        """
        n = int(self.sample_rate * duration)
        t = np.linspace(0, 1, n, False)
        A = (t < 0.2) * (t/0.2)                        # 0â†’1
        B = ((t >= 0.2) & (t < 0.7)) * 1.0             # ç¨³æ€
        Ap = (t >= 0.7) * (0.7 + 0.3*(t-0.7)/0.3)      # 0.7â†’1.0
        env = A + B + Ap
        return np.clip(env / env.max(), 0, 1)

    def _safe_place(self, segment: np.ndarray, start_time: float, total_duration: float) -> np.ndarray:
        """æŠŠ segment å®‰å…¨è´´åˆ°é•¿åº¦ä¸º total_duration çš„æ—¶é—´è½´ä¸Šï¼Œè‡ªåŠ¨å¤„ç†è¾¹ç•Œä¸é›¶é•¿åˆ‡ç‰‡ã€‚"""
        total = int(self.sample_rate * total_duration)
        out = np.zeros(total, dtype=float)
        if segment is None or len(segment) == 0 or total <= 0:
            return out
        start = int(round(start_time * self.sample_rate))
        # å…è®¸æå°è´Ÿèµ·ç‚¹ï¼ˆäººæ€§åŒ–æŠ–åŠ¨å¯¼è‡´ï¼‰
        if start < 0:
            segment = segment[-start:]
            start = 0
        if start >= total:
            return out
        end = min(start + len(segment), total)
        if end <= start:
            return out
        out[start:end] = segment[:end - start]
        return out
    
    def generate_expressive_note(self, frequency, duration, amplitude):
        """ç”Ÿæˆæœ‰è¡¨ç°åŠ›çš„éŸ³ç¬¦"""
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples, False)
        
        # åŸºç¡€éŸ³ç¬¦
        fundamental = amplitude * np.sin(2 * np.pi * frequency * t)
        
        # æ·»åŠ è°æ³¢ä¸°å¯ŒéŸ³è‰²
        harmonic2 = amplitude * 0.3 * np.sin(2 * np.pi * frequency * 2 * t)
        harmonic3 = amplitude * 0.2 * np.sin(2 * np.pi * frequency * 3 * t)
        
        # è¡¨ç°åŠ›åŒ…ç»œï¼ˆæ¨¡æ‹ŸçœŸå®ä¹å™¨ï¼‰
        attack_time = 0.1
        decay_time = 0.2
        sustain_level = 0.7
        
        attack_samples = int(attack_time * self.sample_rate)
        decay_samples = int(decay_time * self.sample_rate)
        
        envelope = np.ones(samples) * sustain_level
        
        # ADSRåŒ…ç»œ
        if attack_samples > 0:
            envelope[:attack_samples] = np.linspace(0, 1, attack_samples)
        
        if decay_samples > 0 and attack_samples + decay_samples < samples:
            decay_start = attack_samples
            decay_end = attack_samples + decay_samples
            envelope[decay_start:decay_end] = np.linspace(1, sustain_level, decay_samples)
        
        # æ·»åŠ é¢¤éŸ³
        vibrato = 1 + 0.05 * np.sin(2 * np.pi * 5 * t)
        
        note_sound = (fundamental + harmonic2 + harmonic3) * envelope * vibrato
        
        return note_sound
    
    def create_kick_drum(self, start_time, amplitude, total_duration):
        """åˆ›å»ºåº•é¼“éŸ³è‰²"""
        duration = 0.3
        samples = int(self.sample_rate * duration)
        
        t = np.linspace(0, duration, samples, False)  # ä¸å«ç«¯ç‚¹
        
        # ä½é¢‘æ­£å¼¦æ³¢ + å¿«é€Ÿè¡°å‡åŒ…ç»œ
        frequency = 60 * np.exp(-t * 8)  # é¢‘ç‡ä»60Hzå¿«é€Ÿä¸‹é™
        kick = amplitude * np.sin(2 * np.pi * frequency * t) * np.exp(-t * 6)
        
        # æ·»åŠ ç‚¹å‡»éŸ³
        click = amplitude * 0.3 * np.random.normal(0, 1, samples) * np.exp(-t * 20)
        kick += click
        
        return self._safe_place(kick, start_time, total_duration)
    
    def create_snare_drum(self, start_time, amplitude, total_duration):
        """åˆ›å»ºå†›é¼“éŸ³è‰²"""
        duration = 0.2
        samples = int(self.sample_rate * duration)
        
        t = np.linspace(0, duration, samples, False)  # ä¸å«ç«¯ç‚¹
        
        # ä¸­é¢‘æ­£å¼¦æ³¢ + å™ªéŸ³
        tone = amplitude * 0.4 * np.sin(2 * np.pi * 200 * t) * np.exp(-t * 8)
        noise = amplitude * 0.6 * np.random.normal(0, 1, samples) * np.exp(-t * 10)
        snare = tone + noise
        
        return self._safe_place(snare, start_time, total_duration)
    
    def create_hihat(self, start_time, amplitude, total_duration):
        """åˆ›å»ºé«˜å¸½éŸ³è‰²"""
        duration = 0.1
        samples = int(self.sample_rate * duration)
        
        t = np.linspace(0, duration, samples, False)  # ä¸å«ç«¯ç‚¹
        
        # é«˜é¢‘å™ªéŸ³
        hihat = amplitude * np.random.normal(0, 1, samples) * np.exp(-t * 15)
        
        # é«˜é€šæ»¤æ³¢æ•ˆæœï¼ˆç®€åŒ–ï¼‰
        hihat = hihat * (1 - np.exp(-t * 50))
        
        return self._safe_place(hihat, start_time, total_duration)
    
    def generate_string_section(self, duration=30, style="mysterious"):
        """ç”Ÿæˆå¼¦ä¹å£°éƒ¨"""
        # å¼¦ä¹å’Œå¼¦è¿›è¡Œï¼ˆæ¯”ä¸»å’Œå¼¦é«˜ä¸€ä¸ªå…«åº¦ï¼‰
        progressions = {
            "mysterious": [[440, 523, 622], [414, 493, 622], [392, 466, 587], [440, 523, 659]],
            "peaceful": [[523, 659, 784], [440, 554, 659], [493, 622, 740], [587, 698, 880]],
            "tense": [[466, 554, 698], [415, 493, 622], [370, 440, 554], [392, 466, 587]],
            "hopeful": [[523, 659, 784], [587, 698, 880], [440, 554, 659], [493, 622, 740]]
        }
        
        progression = progressions.get(style, progressions["mysterious"])
        chord_duration = duration / len(progression)
        audio_data = np.array([])
        
        for chord_freqs in progression:
            # å¼¦ä¹ç‰¹æœ‰çš„ç¼“æ…¢attack
            string_chord = self.generate_string_chord(chord_freqs, chord_duration, 0.08)
            audio_data = np.concatenate([audio_data, string_chord])
        
        return audio_data
    
    def generate_string_chord(self, frequencies, duration, amplitude):
        """ç”Ÿæˆå¼¦ä¹å’Œå¼¦"""
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples, False)
        
        chord_data = np.zeros(samples)
        
        for freq in frequencies:
            # åŸºç¡€æ­£å¼¦æ³¢
            fundamental = amplitude * np.sin(2 * np.pi * freq * t)
            
            # æ·»åŠ å¼¦ä¹ç‰¹æœ‰çš„è°æ³¢
            harmonic2 = amplitude * 0.3 * np.sin(2 * np.pi * freq * 2 * t)
            harmonic3 = amplitude * 0.2 * np.sin(2 * np.pi * freq * 3 * t)
            
            # å¼¦ä¹çš„æ…¢attackåŒ…ç»œ
            attack_time = duration * 0.3
            attack_samples = int(attack_time * self.sample_rate)
            envelope = np.ones(samples)
            if attack_samples > 0:
                envelope[:attack_samples] = np.linspace(0, 1, attack_samples)
            
            string_voice = (fundamental + harmonic2 + harmonic3) * envelope
            chord_data += string_voice
        
        return chord_data / len(frequencies)
    
    def generate_piano_arpeggios(self, duration=30, style="mysterious"):
        """ç”Ÿæˆé’¢ç´ç¶éŸ³"""
        progressions = {
            "mysterious": [220, 261, 311, 261, 246, 293, 349, 293, 196, 233, 293, 233],
            "peaceful": [261, 329, 392, 329, 220, 277, 329, 277, 246, 311, 369, 311],
            "tense": [233, 277, 349, 277, 207, 246, 311, 246, 185, 220, 277, 220],
            "hopeful": [261, 329, 392, 329, 293, 369, 440, 369, 220, 277, 329, 277]
        }
        
        notes = progressions.get(style, progressions["mysterious"])
        note_duration = duration / len(notes)
        audio_data = np.array([])
        
        for freq in notes:
            piano_note = self.generate_piano_note(freq, note_duration, 0.1)
            audio_data = np.concatenate([audio_data, piano_note])
        
        return audio_data
    
    def generate_piano_note(self, frequency, duration, amplitude):
        """ç”Ÿæˆé’¢ç´éŸ³ç¬¦"""
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples, False)
        
        # é’¢ç´çš„å¤æ‚è°æ³¢ç»“æ„
        fundamental = amplitude * np.sin(2 * np.pi * frequency * t)
        harmonic2 = amplitude * 0.5 * np.sin(2 * np.pi * frequency * 2 * t)
        harmonic3 = amplitude * 0.25 * np.sin(2 * np.pi * frequency * 3 * t)
        harmonic4 = amplitude * 0.125 * np.sin(2 * np.pi * frequency * 4 * t)
        
        # é’¢ç´çš„å¿«attackï¼Œæ…¢decayåŒ…ç»œ
        attack_time = 0.05
        attack_samples = int(attack_time * self.sample_rate)
        
        envelope = np.exp(-t * 2)  # æŒ‡æ•°è¡°å‡
        if attack_samples > 0:
            envelope[:attack_samples] *= np.linspace(0, 1, attack_samples)
        
        piano_sound = (fundamental + harmonic2 + harmonic3 + harmonic4) * envelope
        
        return piano_sound
    
    def generate_ambient_texture(self, duration=30):
        """ç”Ÿæˆç¯å¢ƒçº¹ç†éŸ³æ•ˆ"""
        samples = int(self.sample_rate * duration)
        
        # ç”Ÿæˆç²‰çº¢å™ªéŸ³ï¼ˆæ¯”ç™½å™ªéŸ³æ›´è‡ªç„¶ï¼‰
        white_noise = np.random.normal(0, 0.05, samples)
        
        # ç®€å•çš„ç²‰çº¢å™ªéŸ³æ»¤æ³¢
        b = [0.049922035, -0.095993537, 0.050612699, -0.004408786]
        a = [1, -2.494956002, 2.017265875, -0.522189400]
        
        # ç®€åŒ–çš„æ»¤æ³¢å¤„ç†
        pink_noise = white_noise * 0.1
        
        # æ·»åŠ ç¼“æ…¢çš„éŸ³é‡å˜åŒ–
        t = np.linspace(0, duration, samples, False)
        volume_env = 0.3 + 0.2 * np.sin(2 * np.pi * t / (duration/3))
        
        ambient_texture = pink_noise * volume_env
        
        return ambient_texture
    
    def save_audio(self, audio_data, filename):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        # è½¬æ¢ä¸º16ä½æ•´æ•°
        audio_16bit = (audio_data * 32767).astype(np.int16)
        
        with wave.open(filename, 'w') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16ä½
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes(audio_16bit.tobytes())
    
    def add_subtle_modulation(self, audio_data, duration):
        """æ·»åŠ ç»†å¾®çš„è°ƒåˆ¶æ•ˆæœ"""
        t = np.linspace(0, duration, len(audio_data))
        
        # LFO (ä½é¢‘æŒ¯è¡å™¨) ç”¨äºéŸ³é‡è°ƒåˆ¶
        lfo = 1 + 0.05 * np.sin(2 * np.pi * 0.3 * t)  # 0.3Hzçš„æ…¢é€Ÿè°ƒåˆ¶
        
        # ç»†å¾®çš„é¢¤éŸ³æ•ˆæœ
        vibrato = 1 + 0.02 * np.sin(2 * np.pi * 5 * t)  # 5Hzé¢¤éŸ³
        
        return audio_data * lfo * vibrato

    def generate_youtube_bgm(self, style="mysterious", duration=30, filename="youtube_bgm.wav"):
        """ç”ŸæˆYouTubeèƒŒæ™¯éŸ³ä¹ - åŠ¨æ€å¢å¼ºç‰ˆ"""
        print(self.i18n.t('bgm_generation_style', style=style))
        print(self.i18n.t('bgm_generation_duration', duration=duration))
        print(self.i18n.t('bgm_generation_filename', filename=filename))
        print(self.i18n.t('bgm_generation_processing'))
        
        # ç¡®ä¿æ‰€æœ‰éŸ³è½¨é•¿åº¦ä¸€è‡´
        target_samples = int(self.sample_rate * duration)
        
        # 1. ç”ŸæˆåŠ¨æ€ä¸»æ—‹å¾‹ï¼ˆé«˜çº§æ—‹å¾‹å¼•æ“ï¼‰
        print(self.i18n.t('bgm_generation_melody'))
        melody = self.generate_dynamic_melody(duration, style, complexity=4, seed=None)
        melody = self.ensure_length(melody, target_samples)
        
        # å¯é€‰ï¼šå¯¹ä½
        print(self.i18n.t('bgm_generation_counter'))
        counter_melody = self.generate_counter_melody(duration, style, complexity=3)
        counter_melody = self.ensure_length(counter_melody, target_samples)
        
        # 2. ç”ŸæˆåŠ¨æ€ä½éŸ³çº¿
        print(self.i18n.t('bgm_generation_bass'))
        bass = self.generate_bass_line(duration, style)
        bass = self.ensure_length(bass, target_samples)
        
        # 3. ç”Ÿæˆå’Œå£°éŸ³å«
        print(self.i18n.t('bgm_generation_pad'))
        main_pad = self.generate_ambient_pad(duration, style)
        main_pad = self.ensure_length(main_pad, target_samples)
        
        # 4. ç”Ÿæˆå¼¦ä¹å£°éƒ¨
        print(self.i18n.t('bgm_generation_strings'))
        strings = self.generate_string_section(duration, style)
        strings = self.ensure_length(strings, target_samples)
        
        # 5. ç”Ÿæˆé’¢ç´ç¶éŸ³
        print(self.i18n.t('bgm_generation_piano'))
        piano = self.generate_piano_arpeggios(duration, style)
        piano = self.ensure_length(piano, target_samples)
        
        # 6. ç”ŸæˆåŠ¨æ€é¼“ç‚¹
        print(self.i18n.t('bgm_generation_drums'))
        drums = self.generate_drum_pattern(duration, style)
        drums = self.ensure_length(drums, target_samples)
        
        # 7. ç”Ÿæˆç¯å¢ƒçº¹ç†
        print(self.i18n.t('bgm_generation_texture'))
        texture = self.generate_ambient_texture(duration)
        texture = self.ensure_length(texture, target_samples)
        
        # 7.5 ç”Ÿæˆç®¡å¼¦å±‚
        print(self.i18n.t('bgm_generation_orchestral'))
        orch = self.generate_orchestral_layer(duration, style)
        
        # ç¡®ä¿ç®¡å¼¦å±‚é•¿åº¦ä¸€è‡´
        for k in orch:
            orch[k] = self.ensure_length(orch[k], target_samples)
        
        # åˆ†æ®µæ¨è¿›åŒ…ç»œ
        seg_env = self._section_envelope(duration, scheme="ABA")
        
        # åŠ¨æ€æ··éŸ³ - ä¸åŒé£æ ¼çš„ä¹å™¨å¹³è¡¡å’ŒåŠ¨æ€å˜åŒ–
        print(self.i18n.t('bgm_generation_mixing'))
        if style == "mysterious":
            mixed_audio = (melody * 0.30 +
                          counter_melody * 0.12 +
                          bass * 0.35 +
                          main_pad * 0.20 +
                          strings * 0.15 +
                          piano * 0.10 +
                          drums * 0.30 +
                          texture * 0.15 +
                          (orch["strings_hi"] * 0.22 + orch["choir"] * 0.18 +
                           orch["brass"] * 0.16 + orch["pluck"] * 0.12) * seg_env)
        elif style == "tense":
            mixed_audio = (melody * 0.35 +
                          counter_melody * 0.10 +
                          bass * 0.40 +
                          main_pad * 0.15 +
                          strings * 0.25 +
                          piano * 0.05 +
                          drums * 0.50 +
                          texture * 0.10 +
                          (orch["strings_hi"] * 0.20 + orch["choir"] * 0.12 +
                           orch["brass"] * 0.22 + orch["pluck"] * 0.10) * seg_env)
        elif style == "peaceful":
            mixed_audio = (melody * 0.25 +
                          counter_melody * 0.15 +
                          bass * 0.20 +
                          main_pad * 0.40 +
                          strings * 0.30 +
                          piano * 0.25 +
                          drums * 0.10 +
                          texture * 0.25 +
                          (orch["strings_hi"] * 0.24 + orch["choir"] * 0.22 +
                           orch["brass"] * 0.08 + orch["pluck"] * 0.10) * seg_env)
        else:  # hopeful
            mixed_audio = (melody * 0.40 +
                          counter_melody * 0.15 +
                          bass * 0.25 +
                          main_pad * 0.20 +
                          strings * 0.20 +
                          piano * 0.30 +
                          drums * 0.40 +
                          texture * 0.10 +
                          (orch["strings_hi"] * 0.20 + orch["choir"] * 0.14 +
                           orch["brass"] * 0.18 + orch["pluck"] * 0.12) * seg_env)
        
        # æ·»åŠ åŠ¨æ€éŸ³é‡å˜åŒ–ï¼ˆè®©æ•´é¦–æ›²å­æœ‰èµ·ä¼ï¼‰
        t = np.linspace(0, duration, len(mixed_audio))
        dynamic_envelope = 0.8 + 0.2 * np.sin(2 * np.pi * t / (duration/2))  # æ…¢é€ŸéŸ³é‡å˜åŒ–
        mixed_audio *= dynamic_envelope
        
        # æ•´ä½“æ·¡å…¥æ·¡å‡º
        fade_samples = int(2 * self.sample_rate)  # 2ç§’æ·¡å…¥æ·¡å‡º
        if len(mixed_audio) > fade_samples * 2:
            fade_in = np.linspace(0, 1, fade_samples)
            fade_out = np.linspace(1, 0, fade_samples)
            
            mixed_audio[:fade_samples] *= fade_in
            mixed_audio[-fade_samples:] *= fade_out
        
        # æœ€ç»ˆè°ƒåˆ¶å’ŒåŠ¨æ€å‹ç¼©
        mixed_audio = self.add_subtle_modulation(mixed_audio, duration)
        
        # åŠ¨æ€èŒƒå›´å‹ç¼©ï¼ˆè®©éŸ³ä¹æ›´ç´§å‡‘ï¼‰
        mixed_audio = self.compress_dynamics(mixed_audio)
        
        # ä¿å­˜æ–‡ä»¶
        self.save_audio(mixed_audio, filename)
        
        file_size = os.path.getsize(filename) / (1024 * 1024)
        print(self.i18n.t('bgm_completion_success'))
        print(self.i18n.t('bgm_completion_features'))
        print(self.i18n.t('bgm_completion_orchestral'))
        print(self.i18n.t('bgm_completion_characteristics'))
        print(self.i18n.t('bgm_completion_melody'))
        print(self.i18n.t('bgm_completion_structure'))
        print(self.i18n.t('bgm_completion_filesize', size=file_size))
        print(self.i18n.t('bgm_completion_location', path=os.path.abspath(filename)))
        
        return filename
    
    def compress_dynamics(self, audio_data, ratio=3.0, threshold=0.7):
        """åŠ¨æ€èŒƒå›´å‹ç¼©"""
        # ç®€å•çš„å‹ç¼©å™¨
        compressed = audio_data.copy()
        
        # æ‰¾åˆ°è¶…è¿‡é˜ˆå€¼çš„éƒ¨åˆ†
        over_threshold = np.abs(compressed) > threshold
        
        # å¯¹è¶…è¿‡é˜ˆå€¼çš„éƒ¨åˆ†è¿›è¡Œå‹ç¼©
        compressed[over_threshold] = np.sign(compressed[over_threshold]) * (
            threshold + (np.abs(compressed[over_threshold]) - threshold) / ratio
        )
        
        return compressed
    
    def ensure_length(self, audio_array, target_length):
        """ç¡®ä¿éŸ³é¢‘æ•°ç»„é•¿åº¦ä¸€è‡´"""
        current_length = len(audio_array)
        
        if current_length == target_length:
            return audio_array
        elif current_length < target_length:
            # å¦‚æœå¤ªçŸ­ï¼Œç”¨é›¶å¡«å……
            return np.pad(audio_array, (0, target_length - current_length), mode='constant')
        else:
            # å¦‚æœå¤ªé•¿ï¼Œæˆªæ–­
            return audio_array[:target_length]

class BackgroundMusicGUI:
    """èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨ GUI ç•Œé¢"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.generator = SimpleBackgroundMusicGenerator()
        self.setup_ui()
        self.update_language()
        
    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        self.root.title(lang.get('bgm_title', 'è½»é‡çº§èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨'))
        self.root.geometry("600x500")
        self.root.resizable(True, True)
        
        # å±…ä¸­æ˜¾ç¤ºçª—å£
        self.center_window()
        
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="20")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®ç½‘æ ¼æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        
        # è¯­è¨€åˆ‡æ¢æŒ‰é’®ï¼ˆå³ä¸Šè§’ï¼‰
        self.create_language_selector(main_frame)
        
        # æ ‡é¢˜
        self.title_var = tk.StringVar(value=lang.get('bgm_title', 'è½»é‡çº§èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨'))
        title_label = ttk.Label(main_frame, textvariable=self.title_var, 
                               font=('Arial', 16, 'bold'))
        title_label.grid(row=1, column=0, columnspan=3, pady=(0, 10))
        
        self.subtitle_var = tk.StringVar(value=lang.get('bgm_subtitle', 'ä¸“ä¸ºYouTubeçŸ­è§†é¢‘è®¾è®¡'))
        subtitle_label = ttk.Label(main_frame, textvariable=self.subtitle_var)
        subtitle_label.grid(row=2, column=0, columnspan=3, pady=(0, 20))
        
        # é£æ ¼é€‰æ‹©
        self.styles_title_var = tk.StringVar(value=lang.get('bgm_styles_title', 'å¯ç”¨é£æ ¼:'))
        ttk.Label(main_frame, textvariable=self.styles_title_var).grid(row=3, column=0, sticky=tk.W, pady=5)
        
        self.style_var = tk.StringVar(value="mysterious")
        style_frame = ttk.Frame(main_frame)
        style_frame.grid(row=3, column=1, columnspan=2, sticky=(tk.W, tk.E), pady=5)
        
        self.style_buttons = {}
        styles = [
            ("mysterious", "bgm_styles_mysterious"),
            ("peaceful", "bgm_styles_peaceful"), 
            ("tense", "bgm_styles_tense"),
            ("hopeful", "bgm_styles_hopeful")
        ]
        
        for i, (style_id, lang_key) in enumerate(styles):
            btn = ttk.Radiobutton(style_frame, text=lang.get(lang_key, style_id), 
                                 variable=self.style_var, value=style_id)
            btn.grid(row=0, column=i, padx=5, sticky=tk.W)
            self.style_buttons[style_id] = btn
        
        # æ—¶é•¿è®¾ç½®
        self.duration_label_var = tk.StringVar(value=lang.get('bgm_input_duration', 'éŸ³ä¹æ—¶é•¿ (ç§’):'))
        ttk.Label(main_frame, textvariable=self.duration_label_var).grid(row=4, column=0, sticky=tk.W, pady=5)
        self.duration_var = tk.StringVar(value="30")
        duration_entry = ttk.Entry(main_frame, textvariable=self.duration_var, width=10)
        duration_entry.grid(row=4, column=1, sticky=tk.W, pady=5)
        
        # æ–‡ä»¶åè®¾ç½®
        self.filename_label_var = tk.StringVar(value=lang.get('bgm_input_filename', 'è¾“å‡ºæ–‡ä»¶å:'))
        ttk.Label(main_frame, textvariable=self.filename_label_var).grid(row=5, column=0, sticky=tk.W, pady=5)
        filename_frame = ttk.Frame(main_frame)
        filename_frame.grid(row=5, column=1, columnspan=2, sticky=(tk.W, tk.E), pady=5)
        filename_frame.columnconfigure(0, weight=1)
        
        self.filename_var = tk.StringVar(value="bgm_mysterious.wav")
        filename_entry = ttk.Entry(filename_frame, textvariable=self.filename_var)
        filename_entry.grid(row=0, column=0, sticky=(tk.W, tk.E), padx=(0, 5))
        
        self.browse_btn = ttk.Button(filename_frame, text=lang.get('bgm_browse', 'æµè§ˆ'), command=self.browse_file)
        self.browse_btn.grid(row=0, column=1)
        
        # ç”ŸæˆæŒ‰é’®
        self.generate_btn = ttk.Button(main_frame, text=lang.get('bgm_generation_start', 'å¼€å§‹ç”Ÿæˆ'), 
                                      command=self.start_generation, style='Accent.TButton')
        self.generate_btn.grid(row=6, column=0, columnspan=3, pady=20)
        
        # è¿›åº¦æ¡
        self.progress_var = tk.StringVar(value="")
        progress_label = ttk.Label(main_frame, textvariable=self.progress_var)
        progress_label.grid(row=7, column=0, columnspan=3, pady=5)
        
        self.progress_bar = ttk.Progressbar(main_frame, mode='indeterminate')
        self.progress_bar.grid(row=8, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        # çŠ¶æ€æ˜¾ç¤º
        self.status_var = tk.StringVar(value="")
        status_label = ttk.Label(main_frame, textvariable=self.status_var, foreground='green')
        status_label.grid(row=9, column=0, columnspan=3, pady=5)
        
        # ç»‘å®šäº‹ä»¶
        self.style_var.trace('w', self.on_style_change)
        
    def center_window(self):
        """çª—å£å±…ä¸­æ˜¾ç¤º"""
        self.root.update_idletasks()
        width = self.root.winfo_width()
        height = self.root.winfo_height()
        x = (self.root.winfo_screenwidth() // 2) - (width // 2)
        y = (self.root.winfo_screenheight() // 2) - (height // 2)
        self.root.geometry(f'{width}x{height}+{x}+{y}')
        
    def create_language_selector(self, parent):
        """åˆ›å»ºè¯­è¨€é€‰æ‹©å™¨"""
        lang_frame = ttk.Frame(parent)
        lang_frame.grid(row=0, column=2, sticky=tk.E, pady=5)
        
        current_lang = get_saved_language()
        lang_text = lang.get('bgm_language_zh', 'ä¸­æ–‡') if current_lang == "zh" else lang.get('bgm_language_en', 'English')
        
        self.lang_btn = ttk.Button(lang_frame, text=lang_text, command=self.toggle_language)
        self.lang_btn.pack()
        
    def toggle_language(self):
        """åˆ‡æ¢è¯­è¨€"""
        current_lang = get_saved_language()
        new_lang = "en" if current_lang == "zh" else "zh"
        
        if switch_language(new_lang):
            self.update_language()
            messagebox.showinfo(lang.get('bgm_success', 'æˆåŠŸ'), lang.get('bgm_language_switched', f'è¯­è¨€å·²åˆ‡æ¢ä¸º: {new_lang}'))
            
    def update_language(self):
        """æ›´æ–°ç•Œé¢è¯­è¨€"""
        # æ›´æ–°çª—å£æ ‡é¢˜
        self.root.title(lang.get('bgm_title', 'è½»é‡çº§èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨'))
        
        # æ›´æ–°è¯­è¨€æŒ‰é’®
        current_lang = get_saved_language()
        lang_text = lang.get('bgm_language_zh', 'ä¸­æ–‡') if current_lang == "zh" else lang.get('bgm_language_en', 'English')
        self.lang_btn.config(text=lang_text)
        
        # æ›´æ–°æ‰€æœ‰æ–‡æœ¬
        for style_id, btn in self.style_buttons.items():
            lang_key = f"bgm_styles_{style_id}"
            btn.config(text=lang.get(lang_key, style_id))
            
        # æ›´æ–°å…¶ä»–æ§ä»¶æ–‡æœ¬
        self.generate_btn.config(text=lang.get('bgm_generation_start', 'å¼€å§‹ç”Ÿæˆ'))
        
        # æ›´æ–°æ‰€æœ‰æ ‡ç­¾æ–‡æœ¬ - éœ€è¦é‡æ–°åˆ›å»ºæˆ–æ›´æ–°æ ‡ç­¾
        self.update_all_labels()
        
    def update_all_labels(self):
        """æ›´æ–°æ‰€æœ‰æ ‡ç­¾çš„æ–‡æœ¬"""
        # æ›´æ–°æ ‡é¢˜å’Œå‰¯æ ‡é¢˜
        self.title_var.set(lang.get('bgm_title', 'è½»é‡çº§èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå™¨'))
        self.subtitle_var.set(lang.get('bgm_subtitle', 'ä¸“ä¸ºYouTubeçŸ­è§†é¢‘è®¾è®¡'))
        
        # æ›´æ–°æ ‡ç­¾
        self.styles_title_var.set(lang.get('bgm_styles_title', 'å¯ç”¨é£æ ¼:'))
        self.duration_label_var.set(lang.get('bgm_input_duration', 'éŸ³ä¹æ—¶é•¿ (ç§’):'))
        self.filename_label_var.set(lang.get('bgm_input_filename', 'è¾“å‡ºæ–‡ä»¶å:'))
        
        # æ›´æ–°æŒ‰é’®
        self.browse_btn.config(text=lang.get('bgm_browse', 'æµè§ˆ'))
        self.generate_btn.config(text=lang.get('bgm_generation_start', 'å¼€å§‹ç”Ÿæˆ'))
        
    def on_style_change(self, *args):
        """é£æ ¼æ”¹å˜æ—¶çš„å›è°ƒ"""
        style = self.style_var.get()
        self.filename_var.set(f"bgm_{style}.wav")
        
    def browse_file(self):
        """æµè§ˆæ–‡ä»¶å¯¹è¯æ¡†"""
        filename = filedialog.asksaveasfilename(
            title=lang.get('bgm_file_dialog_title', 'é€‰æ‹©è¾“å‡ºæ–‡ä»¶'),
            defaultextension=".wav",
            filetypes=[("WAV files", "*.wav"), ("All files", "*.*")]
        )
        if filename:
            self.filename_var.set(filename)
            
    def start_generation(self):
        """å¼€å§‹ç”ŸæˆéŸ³ä¹"""
        try:
            # éªŒè¯è¾“å…¥
            duration = int(self.duration_var.get())
            if duration <= 0:
                messagebox.showerror(lang.get('bgm_error', 'é”™è¯¯'), lang.get('bgm_error_duration', 'æ—¶é•¿å¿…é¡»å¤§äº0'))
                return
                
            filename = self.filename_var.get()
            if not filename:
                messagebox.showerror(lang.get('bgm_error', 'é”™è¯¯'), lang.get('bgm_error_filename', 'è¯·è¾“å…¥æ–‡ä»¶å'))
                return
                
            if not filename.endswith('.wav'):
                filename += '.wav'
                self.filename_var.set(filename)
                
            # ç¦ç”¨ç”ŸæˆæŒ‰é’®
            self.generate_btn.config(state='disabled')
            self.progress_bar.start()
            self.progress_var.set(lang.get('bgm_generation_processing', 'æ­£åœ¨ç”Ÿæˆ...'))
            self.status_var.set("")
            
            # åœ¨æ–°çº¿ç¨‹ä¸­ç”ŸæˆéŸ³ä¹
            thread = threading.Thread(target=self.generate_music, args=(duration, filename))
            thread.daemon = True
            thread.start()
            
        except ValueError:
            messagebox.showerror(lang.get('bgm_error', 'é”™è¯¯'), lang.get('bgm_error_duration_invalid', 'è¯·è¾“å…¥æœ‰æ•ˆçš„æ—¶é•¿'))
            self.generate_btn.config(state='normal')
            self.progress_bar.stop()
            
    def generate_music(self, duration, filename):
        """ç”ŸæˆéŸ³ä¹ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        try:
            style = self.style_var.get()
            
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress_var.set(lang.get('bgm_generation_style', f'ç”Ÿæˆé£æ ¼: {style}')))
            
            # ç”ŸæˆéŸ³ä¹
            result = self.generator.generate_youtube_bgm(style, duration, filename)
            
            # æ›´æ–°çŠ¶æ€
            self.root.after(0, lambda: self.progress_var.set(lang.get('bgm_completion_success', 'ç”Ÿæˆå®Œæˆ!')))
            self.root.after(0, lambda: self.status_var.set(lang.get('bgm_completion_final', 'èƒŒæ™¯éŸ³ä¹ç”Ÿæˆå®Œæˆ!')))
            
        except Exception as e:
            error_msg = lang.get('bgm_interaction_error', f'ç¨‹åºè¿è¡Œå‡ºé”™: {e}')
            self.root.after(0, lambda: messagebox.showerror(lang.get('bgm_error', 'é”™è¯¯'), error_msg))
            self.root.after(0, lambda: self.status_var.set(lang.get('bgm_generation_failed', 'ç”Ÿæˆå¤±è´¥')))
            
        finally:
            # æ¢å¤ç•Œé¢
            self.root.after(0, lambda: self.generate_btn.config(state='normal'))
            self.root.after(0, lambda: self.progress_bar.stop())
            self.root.after(0, lambda: self.progress_var.set(""))
            
    def run(self):
        """è¿è¡ŒGUI"""
        self.root.mainloop()

def main():
    """ä¸»å‡½æ•° - å¯åŠ¨GUIç•Œé¢"""
    try:
        # å¯åŠ¨GUIç•Œé¢
        app = BackgroundMusicGUI()
        app.run()
    except Exception as e:
        print(_I18N.t('bgm_gui_start_failed', error=e))
        # å¦‚æœGUIå¯åŠ¨å¤±è´¥ï¼Œå›é€€åˆ°å‘½ä»¤è¡Œæ¨¡å¼
        print(_I18N.t('bgm_fallback_cli'))
        main_cli()

def main_cli():
    """å‘½ä»¤è¡Œæ¨¡å¼ï¼ˆå¤‡ç”¨ï¼‰"""
    # ä½¿ç”¨å…¨å±€å›½é™…åŒ–ç®¡ç†å™¨
    i18n = _I18N
    
    print(i18n.t('bgm_title'))
    print(i18n.t('bgm_subtitle'))
    print(i18n.t('bgm_description'))
    print("="*50)
    
    # è¯­è¨€é€‰æ‹©
    print(f"\n{i18n.t('bgm_language_current')}")
    lang_choice = input(i18n.t('bgm_language_switch')).strip()
    if lang_choice == '2':
        i18n.switch_language('en')
        print(i18n.t('bgm_language_switched', lang=i18n.get_language_name('en')))
    elif lang_choice == '1':
        i18n.switch_language('zh')
        print(i18n.t('bgm_language_switched', lang=i18n.get_language_name('zh')))
    
    generator = SimpleBackgroundMusicGenerator(i18n)
    
    # å¯ç”¨é£æ ¼
    styles = {
        "1": ("mysterious", i18n.t('bgm_styles_mysterious')),
        "2": ("peaceful", i18n.t('bgm_styles_peaceful')),
        "3": ("tense", i18n.t('bgm_styles_tense')),
        "4": ("hopeful", i18n.t('bgm_styles_hopeful'))
    }
    
    print(f"\n{i18n.t('bgm_styles_title')}")
    for key, (style_id, description) in styles.items():
        print(f"  {key}. {description}")
    
    # é€‰æ‹©é£æ ¼
    choice = input(f"\n{i18n.t('bgm_input_select_style')}").strip()
    style_id, style_name = styles.get(choice, ("mysterious", i18n.t('bgm_styles_mysterious')))
    
    # è®¾ç½®æ—¶é•¿
    duration_input = input(i18n.t('bgm_input_duration')).strip()
    duration = int(duration_input) if duration_input.isdigit() else 30
    
    # è®¾ç½®æ–‡ä»¶å
    filename_input = input(i18n.t('bgm_input_filename')).strip()
    filename = filename_input if filename_input else f"bgm_{style_id}.wav"
    if not filename.endswith('.wav'):
        filename += '.wav'
    
    # ç”ŸæˆéŸ³ä¹
    print(f"\nğŸš€ {i18n.t('bgm_generation_start')} {style_name} é£æ ¼çš„èƒŒæ™¯éŸ³ä¹...")
    result = generator.generate_youtube_bgm(style_id, duration, filename)
    
    print(f"\n{i18n.t('bgm_completion_final')}")
    print(i18n.t('bgm_completion_usage'))
    
    # è¯¢é—®æ˜¯å¦ç»§ç»­ç”Ÿæˆ
    if input(f"\n{i18n.t('bgm_interaction_continue')}").lower().startswith('y'):
        main_cli()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n\n{_I18N.t('bgm_interaction_interrupted')}")
    except Exception as e:
        print(f"\n{_I18N.t('bgm_interaction_error', error=e)}")